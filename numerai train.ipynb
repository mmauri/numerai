{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "from lightgbm import LGBMRegressor\r\n",
    "import gc\r\n",
    "from numerapi import NumerAPI\r\n",
    "from halo import Halo\r\n",
    "from utils import save_model, load_model, neutralize, get_biggest_change_features, validation_metrics, download_data\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "napi = NumerAPI()\r\n",
    "spinner = Halo(text='', spinner='dots')\r\n",
    "\r\n",
    "current_round = napi.get_current_round(tournament=8)  # tournament 8 is the primary Numerai Tournament\r\n",
    "print(current_round)\r\n",
    "\r\n",
    "# read in all of the new datas\r\n",
    "# tournament data and example predictions change every week so we specify the round in their names\r\n",
    "# training and validation data only change periodically, so no need to download them over again every single week\r\n",
    "napi.download_dataset(\"numerai_training_data_int8.parquet\", \"numerai_training_data_int8.parquet\")\r\n",
    "napi.download_dataset(\"numerai_tournament_data_int8.parquet\", f\"numerai_tournament_data_{current_round}_int8.parquet\")\r\n",
    "napi.download_dataset(\"numerai_validation_data_int8.parquet\", f\"numerai_validation_data_int8.parquet\")\r\n",
    "napi.download_dataset(\"example_predictions.parquet\", f\"example_predictions_{current_round}.parquet\")\r\n",
    "napi.download_dataset(\"example_validation_predictions.parquet\", \"example_validation_predictions.parquet\")\r\n",
    "\r\n",
    "spinner.start('Reading parquet data')\r\n",
    "training_data = pd.read_parquet('numerai_training_data_int8.parquet')\r\n",
    "tournament_data = pd.read_parquet(f'numerai_tournament_data_{current_round}_int8.parquet')\r\n",
    "validation_data = pd.read_parquet('numerai_validation_data_int8.parquet')\r\n",
    "example_preds = pd.read_parquet(f'example_predictions_{current_round}.parquet')\r\n",
    "validation_preds = pd.read_parquet('example_validation_predictions.parquet')\r\n",
    "spinner.succeed()\r\n",
    "\r\n",
    "EXAMPLE_PREDS_COL = \"example_preds\"\r\n",
    "validation_data[EXAMPLE_PREDS_COL] = validation_preds[\"prediction\"]\r\n",
    "\r\n",
    "TARGET_COL = \"target\"\r\n",
    "ERA_COL = \"era\"\r\n",
    "\r\n",
    "# all feature columns start with the prefix \"feature_\"\r\n",
    "#feature_cols = [c for c in training_data if c.startswith(\"feature_\")]\r\n",
    "\r\n",
    "gc.collect()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "285\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-10-09 21:47:22,380 INFO numerapi.utils: target file already exists\n",
      "2021-10-09 21:47:22,382 INFO numerapi.utils: download complete\n",
      "2021-10-09 21:47:23,297 INFO numerapi.utils: starting download\n",
      "numerai_tournament_data_285_int8.parquet: 582MB [00:18, 31.5MB/s]                           \n",
      "2021-10-09 21:47:42,922 INFO numerapi.utils: target file already exists\n",
      "2021-10-09 21:47:42,923 INFO numerapi.utils: download complete\n",
      "2021-10-09 21:47:44,088 INFO numerapi.utils: starting download\n",
      "example_predictions_285.parquet: 33.5MB [00:01, 16.8MB/s]                            \n",
      "2021-10-09 21:47:46,968 INFO numerapi.utils: target file already exists\n",
      "2021-10-09 21:47:46,969 INFO numerapi.utils: download complete\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "v Reading parquet data\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 1
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": []
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "f=['feature_haziest_lifelike_horseback', 'feature_glare_factional_assessment', 'feature_exorbitant_myeloid_crinkle', 'feature_travelled_semipermeable_perruquier', 'feature_branched_dilatory_sunbelt', 'feature_moralistic_heartier_typhoid', 'feature_introvert_symphysial_assegai', 'feature_gullable_sanguine_incongruity', 'feature_agile_unrespited_gaucho', 'feature_canalicular_peeling_lilienthal', 'feature_unvaried_social_bangkok', 'feature_lofty_acceptable_challenge', 'feature_grandmotherly_circumnavigable_homonymity', 'feature_undivorced_unsatisfying_praetorium', 'feature_unaired_operose_lactoprotein']\r\n",
    "f+=['feature_travelled_semipermeable_perruquier', 'feature_planned_superimposed_bend', 'feature_moralistic_heartier_typhoid', 'feature_crowning_frustrate_kampala', 'feature_unaired_operose_lactoprotein', 'feature_flintier_enslaved_borsch', 'feature_cambial_bigoted_bacterioid', 'feature_jerkwater_eustatic_electrocardiograph', 'feature_unvaried_social_bangkok', 'feature_communicatory_unrecommended_velure', 'feature_lofty_acceptable_challenge', 'feature_grandmotherly_circumnavigable_homonymity', 'feature_antichristian_slangiest_idyllist', 'feature_assenting_darn_arthropod', 'feature_haziest_lifelike_horseback', 'feature_exorbitant_myeloid_crinkle', 'feature_beery_somatologic_elimination', 'feature_silver_handworked_scauper', 'feature_canalicular_peeling_lilienthal', 'feature_undivorced_unsatisfying_praetorium']\r\n",
    "f+=['feature_glare_factional_assessment', 'feature_travelled_semipermeable_perruquier', 'feature_moralistic_heartier_typhoid', 'feature_stylistic_honduran_comprador', 'feature_crowning_frustrate_kampala', 'feature_unaired_operose_lactoprotein', 'feature_flintier_enslaved_borsch', 'feature_unvaried_social_bangkok', 'feature_apomictical_motorized_vaporisation', 'feature_lofty_acceptable_challenge', 'feature_antichristian_slangiest_idyllist', 'feature_store_apteral_isocheim', 'feature_unforbidden_highbrow_kafir', 'feature_buxom_curtained_sienna', 'feature_haziest_lifelike_horseback', 'feature_exorbitant_myeloid_crinkle', 'feature_silver_handworked_scauper', 'feature_canalicular_peeling_lilienthal', 'feature_introvert_symphysial_assegai', 'feature_univalve_abdicant_distrail', 'feature_undivorced_unsatisfying_praetorium']\r\n",
    "f+=['feature_glare_factional_assessment', 'feature_unsealed_suffixal_babar', 'feature_travelled_semipermeable_perruquier', 'feature_moralistic_heartier_typhoid', 'feature_twisty_adequate_minutia', 'feature_flintier_enslaved_borsch', 'feature_slack_calefacient_tableau', 'feature_bhutan_imagism_dolerite', 'feature_unvaried_social_bangkok', 'feature_communicatory_unrecommended_velure', 'feature_lofty_acceptable_challenge', 'feature_grandmotherly_circumnavigable_homonymity', 'feature_chuffier_analectic_conchiolin', 'feature_antichristian_slangiest_idyllist', 'feature_unwonted_trusted_fixative', 'feature_haziest_lifelike_horseback', 'feature_exorbitant_myeloid_crinkle', 'feature_beery_somatologic_elimination', 'feature_winsome_irreproachable_milkfish', 'feature_gullable_sanguine_incongruity', 'feature_silver_handworked_scauper', 'feature_canalicular_peeling_lilienthal', 'feature_introvert_symphysial_assegai', 'feature_undivorced_unsatisfying_praetorium']\r\n",
    "\r\n",
    "feature_cols = list(set(f))\r\n",
    "len(feature_cols)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "metadata": {},
     "execution_count": 2
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": []
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def create_lgbm_regressor(model_name:str):\r\n",
    "    model = load_model(model_name)\r\n",
    "    if not model:\r\n",
    "        print(f\"model not found, training new one\")\r\n",
    "        params = {\"n_estimators\": 2000,\r\n",
    "                \"learning_rate\": 0.01,\r\n",
    "                \"max_depth\": 5,\r\n",
    "                \"num_leaves\": 2 ** 5,\r\n",
    "                \"colsample_bytree\": 0.1}\r\n",
    "\r\n",
    "        model = LGBMRegressor(**params)\r\n",
    "\r\n",
    "        # train on all of train, predict on val, predict on tournament, save the model so we don't have to train next time\r\n",
    "        spinner.start('Training model')\r\n",
    "        model.fit(training_data.loc[:, feature_cols], training_data[TARGET_COL])\r\n",
    "        print(f\"saving new model: {model_name}\")\r\n",
    "        save_model(model, model_name)\r\n",
    "        spinner.succeed()\r\n",
    "\r\n",
    "    # check for nans and fill nans\r\n",
    "    if tournament_data.loc[tournament_data[\"data_type\"] == \"live\", feature_cols].isna().sum().sum():\r\n",
    "        cols_w_nan = tournament_data.loc[tournament_data[\"data_type\"] == \"live\", feature_cols].isna().sum()\r\n",
    "        total_rows = tournament_data[tournament_data[\"data_type\"] == \"live\"]\r\n",
    "        print(f\"Number of nans per column this week: {cols_w_nan[cols_w_nan > 0]}\")\r\n",
    "        print(f\"out of {total_rows} total rows\")\r\n",
    "        print(f\"filling nans with 0.5\")\r\n",
    "        tournament_data.loc[:, feature_cols].fillna(0.5, inplace=True)\r\n",
    "    else:\r\n",
    "        print(\"No nans in the features this week!\")\r\n",
    "\r\n",
    "    return model\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": []
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def save_prediction(model, model_name, neutralize_proportion = 0.8, is_xgbRanker = False, use_pool = False):\r\n",
    "    spinner.start('Predicting on latest data')\r\n",
    "    # double check the feature that the model expects vs what is available\r\n",
    "    # this prevents our pipeline from failing if Numerai adds more data and we don't have time to retrain!\r\n",
    "\r\n",
    "\r\n",
    "    try:\r\n",
    "        model_expected_features = model.booster_.feature_name()\r\n",
    "    except:\r\n",
    "        try:\r\n",
    "            model_expected_features = model.get_booster().feature_names\r\n",
    "        except:\r\n",
    "            model_expected_features = model.feature_names_\r\n",
    "        \r\n",
    "    if set(model_expected_features) != set(feature_cols):\r\n",
    "        print(f\"New features are available! Might want to retrain model {model_name}.\")\r\n",
    "\r\n",
    "    if not use_pool:\r\n",
    "        # if is_xgbRanker:\r\n",
    "            \r\n",
    "        #     for era in validation_data.era.unique():\r\n",
    "        #         print(f\"predicting valid era:{era}\")\r\n",
    "        #         validation_data.loc[validation_data.era == era, f\"preds_{model_name}\"] = \\\r\n",
    "        #             model.predict(validation_data.loc[validation_data.era == era, model_expected_features])\r\n",
    "\r\n",
    "        #     for era in tournament_data.era.unique():\r\n",
    "        #         print(f\"predicting tournament era:{era}\")\r\n",
    "        #         tournament_data.loc[tournament_data.era == era, f\"preds_{model_name}\"] = \\\r\n",
    "        #             model.predict(tournament_data.loc[tournament_data.era == era, model_expected_features])\r\n",
    "        # else:\r\n",
    "        validation_data.loc[:, f\"preds_{model_name}\"] = model.predict(validation_data.loc[:, model_expected_features])\r\n",
    "        tournament_data.loc[:, f\"preds_{model_name}\"] = model.predict(tournament_data.loc[:, model_expected_features])\r\n",
    "    else:\r\n",
    "        #catboost ranker is not compayible with sklearn\r\n",
    "\r\n",
    "        test_pool = Pool(\r\n",
    "            data=validation_data.loc[:, feature_cols],\r\n",
    "            label=validation_data[TARGET_COL],\r\n",
    "            group_id=validation_data.era\r\n",
    "        )\r\n",
    "        validation_data.loc[:, f\"preds_{model_name}\"] = model.predict(test_pool)\r\n",
    "\r\n",
    "        tournament_pool = Pool (\r\n",
    "            data = tournament_data.loc[:, model_expected_features],\r\n",
    "            group_id = tournament_data.era\r\n",
    "        )\r\n",
    "\r\n",
    "        tournament_data.loc[:, f\"preds_{model_name}\"] = model.predict(tournament_pool)\r\n",
    "\r\n",
    "    spinner.succeed()\r\n",
    "\r\n",
    "    spinner.start('Neutralizing to risky features')\r\n",
    "    # getting the per era correlation of each feature vs the target\r\n",
    "    all_feature_corrs = training_data.groupby(ERA_COL).apply(lambda d: d[feature_cols].corrwith(d[TARGET_COL]))\r\n",
    "\r\n",
    "    # find the riskiest features by comparing their correlation vs the target in half 1 and half 2 of training data\r\n",
    "    riskiest_features = get_biggest_change_features(all_feature_corrs, 50)\r\n",
    "\r\n",
    "    # neutralize our predictions to the riskiest features\r\n",
    "    validation_data[f\"preds_{model_name}_neutral_riskiest_50\"] = neutralize(df=validation_data,\r\n",
    "                                                                            columns=[f\"preds_{model_name}\"],\r\n",
    "                                                                            neutralizers=riskiest_features,\r\n",
    "                                                                            proportion=neutralize_proportion,\r\n",
    "                                                                            normalize=True,\r\n",
    "                                                                            era_col=ERA_COL)\r\n",
    "\r\n",
    "    tournament_data[f\"preds_{model_name}_neutral_riskiest_50\"] = neutralize(df=tournament_data,\r\n",
    "                                                                            columns=[f\"preds_{model_name}\"],\r\n",
    "                                                                            neutralizers=riskiest_features,\r\n",
    "                                                                            proportion=neutralize_proportion,\r\n",
    "                                                                            normalize=True,\r\n",
    "                                                                            era_col=ERA_COL)\r\n",
    "    spinner.succeed()\r\n",
    "\r\n",
    "    model_to_submit = f\"preds_{model_name}_neutral_riskiest_50\"\r\n",
    "\r\n",
    "    # rename best model to prediction and rank from 0 to 1 to meet diagnostic/submission file requirements\r\n",
    "    validation_data[\"prediction\"] = validation_data[model_to_submit].rank(pct=True)\r\n",
    "    tournament_data[\"prediction\"] = tournament_data[model_to_submit].rank(pct=True)\r\n",
    "    validation_data[\"prediction\"].to_csv(f\"validation_predictions_{current_round}_{model_to_submit}.csv\")\r\n",
    "    tournament_data[\"prediction\"].to_csv(f\"tournament_predictions_{current_round}_{model_to_submit}.csv\")\r\n",
    "\r\n",
    "    # get some stats about each of our models to compare...\r\n",
    "    # fast_mode=True so that we skip some of the stats that are slower to calculate\r\n",
    "    validation_stats = validation_metrics(validation_data, [model_to_submit], example_col=EXAMPLE_PREDS_COL, fast_mode=True)\r\n",
    "    print(validation_stats[[\"mean\", \"sharpe\"]].to_markdown())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": []
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "#Blitter4 XGBRank\r\n",
    "from xgboost import XGBRanker\r\n",
    "from collections import Counter\r\n",
    "\r\n",
    "\r\n",
    "def create_xgb_ranker(model_name:str):\r\n",
    "    model = load_model(model_name)\r\n",
    "    if not model:\r\n",
    "        print(f\"model not found, training new one\")\r\n",
    "\r\n",
    "                        \r\n",
    "        model = XGBRanker(max_depth=5, learning_rate=0.01, n_estimators=2000, n_jobs=-1, colsample_bytree=0.1)\r\n",
    "        # cdf = training_data.groupby('era').agg(['count'])\r\n",
    "        # group = cdf[cdf.columns[0]].values\r\n",
    "        # del cdf\r\n",
    "        group = Counter(training_data.era).values()\r\n",
    "\r\n",
    "        # train on all of train, predict on val, predict on tournament, save the model so we don't have to train next time\r\n",
    "        spinner.start('Training model')\r\n",
    "        model.fit(training_data.loc[:, feature_cols], training_data[TARGET_COL], group=group)\r\n",
    "        print(f\"saving new model: {model_name}\")\r\n",
    "        save_model(model, model_name)\r\n",
    "        spinner.succeed()\r\n",
    "\r\n",
    "    # check for nans and fill nans\r\n",
    "    if tournament_data.loc[tournament_data[\"data_type\"] == \"live\", feature_cols].isna().sum().sum():\r\n",
    "        cols_w_nan = tournament_data.loc[tournament_data[\"data_type\"] == \"live\", feature_cols].isna().sum()\r\n",
    "        total_rows = tournament_data[tournament_data[\"data_type\"] == \"live\"]\r\n",
    "        print(f\"Number of nans per column this week: {cols_w_nan[cols_w_nan > 0]}\")\r\n",
    "        print(f\"out of {total_rows} total rows\")\r\n",
    "        print(f\"filling nans with 0.5\")\r\n",
    "        tournament_data.loc[:, feature_cols].fillna(0.5, inplace=True)\r\n",
    "    else:\r\n",
    "        print(\"No nans in the features this week!\")\r\n",
    "\r\n",
    "    return model"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": []
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from xgboost import XGBRegressor\r\n",
    "\r\n",
    "def create_xgb_regressor(model_name:str):\r\n",
    "    model = load_model(model_name)\r\n",
    "    if not model:\r\n",
    "        print(f\"model not found, training new one\")\r\n",
    "        params = {\"n_estimators\": 2000,\r\n",
    "                \"learning_rate\": 0.01,\r\n",
    "                \"max_depth\": 5,\r\n",
    "                \"num_leaves\": 2 ** 5,\r\n",
    "                \"colsample_bytree\": 0.1}\r\n",
    "\r\n",
    "        model = XGBRegressor(max_depth=5, learning_rate=0.01, \\\r\n",
    "                        n_estimators=2000, colsample_bytree=0.1) #provar regularitzacions\r\n",
    "\r\n",
    "        # train on all of train, predict on val, predict on tournament, save the model so we don't have to train next time\r\n",
    "        spinner.start('Training model')\r\n",
    "        model.fit(training_data.loc[:, feature_cols], training_data[TARGET_COL])\r\n",
    "        print(f\"saving new model: {model_name}\")\r\n",
    "        save_model(model, model_name)\r\n",
    "        spinner.succeed()\r\n",
    "\r\n",
    "    # check for nans and fill nans\r\n",
    "    if tournament_data.loc[tournament_data[\"data_type\"] == \"live\", feature_cols].isna().sum().sum():\r\n",
    "        cols_w_nan = tournament_data.loc[tournament_data[\"data_type\"] == \"live\", feature_cols].isna().sum()\r\n",
    "        total_rows = tournament_data[tournament_data[\"data_type\"] == \"live\"]\r\n",
    "        print(f\"Number of nans per column this week: {cols_w_nan[cols_w_nan > 0]}\")\r\n",
    "        print(f\"out of {total_rows} total rows\")\r\n",
    "        print(f\"filling nans with 0.5\")\r\n",
    "        tournament_data.loc[:, feature_cols].fillna(0.5, inplace=True)\r\n",
    "    else:\r\n",
    "        print(\"No nans in the features this week!\")\r\n",
    "\r\n",
    "    return model"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": []
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "#BLITTER5 - Catboost regressor\r\n",
    "from catboost import CatBoostRegressor\r\n",
    "\r\n",
    "def create_catboost_regressor(model_name:str):\r\n",
    "\r\n",
    "    model = load_model(model_name)\r\n",
    "    if not model:\r\n",
    "        print(f\"model not found, training new one\")\r\n",
    "\r\n",
    "        model = CatBoostRegressor(max_depth=5, learning_rate=0.01, \\\r\n",
    "                        n_estimators=2000, rsm=0.1) #provar regularitzacions\r\n",
    "\r\n",
    "        # train on all of train, predict on val, predict on tournament, save the model so we don't have to train next time\r\n",
    "        spinner.start('Training model')\r\n",
    "        model.fit(training_data.loc[:, feature_cols], training_data[TARGET_COL])\r\n",
    "        print(f\"saving new model: {model_name}\")\r\n",
    "        save_model(model, model_name)\r\n",
    "        spinner.succeed()\r\n",
    "\r\n",
    "    # check for nans and fill nans\r\n",
    "    if tournament_data.loc[tournament_data[\"data_type\"] == \"live\", feature_cols].isna().sum().sum():\r\n",
    "        cols_w_nan = tournament_data.loc[tournament_data[\"data_type\"] == \"live\", feature_cols].isna().sum()\r\n",
    "        total_rows = tournament_data[tournament_data[\"data_type\"] == \"live\"]\r\n",
    "        print(f\"Number of nans per column this week: {cols_w_nan[cols_w_nan > 0]}\")\r\n",
    "        print(f\"out of {total_rows} total rows\")\r\n",
    "        print(f\"filling nans with 0.5\")\r\n",
    "        tournament_data.loc[:, feature_cols].fillna(0.5, inplace=True)\r\n",
    "    else:\r\n",
    "        print(\"No nans in the features this week!\")\r\n",
    "    return model"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": []
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from catboost import CatBoostRanker, Pool\r\n",
    "\r\n",
    "def create_catboost_ranker(model_name : str, loss_function : str, plot = True, verbose = False):\r\n",
    "    gc.collect()\r\n",
    "    print(f\"predicting {model_name}\")\r\n",
    "    model = load_model(model_name)\r\n",
    "    if not model:\r\n",
    "        print(f\"model not found, training new one\")\r\n",
    "        parameters = {\r\n",
    "            'iterations': 200,\r\n",
    "            'custom_metric': ['NDCG', 'PFound'],\r\n",
    "            'verbose': verbose,\r\n",
    "            'random_seed': 0,\r\n",
    "            'rsm' : 0.1,\r\n",
    "            'learning_rate' : 0.01,\r\n",
    "            'loss_function' : loss_function,\r\n",
    "            #'train_dir' : loss_function\r\n",
    "        }\r\n",
    "\r\n",
    "        train_pool = Pool(\r\n",
    "            data=training_data.loc[:, feature_cols],\r\n",
    "            label=training_data[TARGET_COL],\r\n",
    "            group_id=training_data.era\r\n",
    "        )\r\n",
    "\r\n",
    "        test_pool = Pool(\r\n",
    "            data=validation_data.loc[:, feature_cols],\r\n",
    "            label=validation_data[TARGET_COL],\r\n",
    "            group_id=validation_data.era\r\n",
    "        )\r\n",
    "\r\n",
    "        model = CatBoostRanker(**parameters)\r\n",
    "\r\n",
    "\r\n",
    "        # train on all of train, predict on val, predict on tournament, save the model so we don't have to train next time\r\n",
    "        #spinner.start('Training model')\r\n",
    "        model.fit(train_pool, eval_set=test_pool, early_stopping_rounds=10, plot=plot)\r\n",
    "\r\n",
    "        print(f\"saving new model: {model_name}\")\r\n",
    "        save_model(model, model_name)\r\n",
    "        #spinner.succeed()\r\n",
    "\r\n",
    "    # check for nans and fill nans\r\n",
    "    if tournament_data.loc[tournament_data[\"data_type\"] == \"live\", feature_cols].isna().sum().sum():\r\n",
    "        cols_w_nan = tournament_data.loc[tournament_data[\"data_type\"] == \"live\", feature_cols].isna().sum()\r\n",
    "        total_rows = tournament_data[tournament_data[\"data_type\"] == \"live\"]\r\n",
    "        print(f\"Number of nans per column this week: {cols_w_nan[cols_w_nan > 0]}\")\r\n",
    "        print(f\"out of {total_rows} total rows\")\r\n",
    "        print(f\"filling nans with 0.5\")\r\n",
    "        tournament_data.loc[:, feature_cols].fillna(0.5, inplace=True)\r\n",
    "    else:\r\n",
    "        print(\"No nans in the features this week!\")\r\n",
    "\r\n",
    "    return model"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": []
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "model_name = f\"blitter\"\r\n",
    "model = create_lgbm_regressor(model_name)\r\n",
    "save_prediction(model, model_name)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "No nans in the features this week!\n",
      "v Predicting on latest data\n",
      "v Neutralizing to risky features\n",
      "|                                   |      mean |   sharpe |\n",
      "|:----------------------------------|----------:|---------:|\n",
      "| preds_blitter_neutral_riskiest_50 | 0.0228259 |  1.05479 |\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "model_name = \"blitter1\" #f\"xgboost_bare\"\r\n",
    "model = create_xgb_regressor(model_name)\r\n",
    "save_prediction(model, model_name)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "No nans in the features this week!\n",
      "v Predicting on latest data\n",
      "v Neutralizing to risky features\n",
      "|                                    |      mean |   sharpe |\n",
      "|:-----------------------------------|----------:|---------:|\n",
      "| preds_blitter1_neutral_riskiest_50 | 0.0241834 |  1.04763 |\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "#Ensemble Lgbm + XGBoost ja neutralitzzades\r\n",
    "model_name = \"BLITTER2\"\r\n",
    "\r\n",
    "validation_data.loc[:, f\"preds_{model_name}\"] = validation_data[\"preds_blitter_neutral_riskiest_50\"] * 0.5 + validation_data[\"preds_blitter1_neutral_riskiest_50\"] * 0.5\r\n",
    "tournament_data.loc[:, f\"preds_{model_name}\"] = tournament_data[\"preds_blitter_neutral_riskiest_50\"] * 0.5 + tournament_data[\"preds_blitter1_neutral_riskiest_50\"] * 0.5\r\n",
    "\r\n",
    "model_to_submit = f\"preds_{model_name}_neutral_riskiest_50\"\r\n",
    "\r\n",
    "validation_data[model_to_submit] = validation_data[f\"preds_{model_name}\"]\r\n",
    "tournament_data[model_to_submit] = tournament_data[f\"preds_{model_name}\"]\r\n",
    "\r\n",
    "\r\n",
    "# rename best model to prediction and rank from 0 to 1 to meet diagnostic/submission file requirements\r\n",
    "validation_data[\"prediction\"] = validation_data[model_to_submit].rank(pct=True)\r\n",
    "tournament_data[\"prediction\"] = tournament_data[model_to_submit].rank(pct=True)\r\n",
    "\r\n",
    "validation_data[\"prediction\"].to_csv(f\"validation_predictions_{current_round}_{model_to_submit}.csv\")\r\n",
    "tournament_data[\"prediction\"].to_csv(f\"tournament_predictions_{current_round}_{model_to_submit}.csv\")\r\n",
    "\r\n",
    "validation_stats = validation_metrics(validation_data, [model_to_submit], example_col=EXAMPLE_PREDS_COL, fast_mode=True)\r\n",
    "print(validation_stats[[\"mean\", \"sharpe\"]].to_markdown())\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "|                                    |      mean |   sharpe |\n",
      "|:-----------------------------------|----------:|---------:|\n",
      "| preds_BLITTER2_neutral_riskiest_50 | 0.0239164 |  1.06938 |\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "#Ensemble Lgbm + XGBoost ensemble after rank\r\n",
    "model_name = \"BLITTER3\"\r\n",
    "\r\n",
    "#ensemble on ranks\r\n",
    "validation_data.loc[:, f\"preds_{model_name}\"] = validation_data[\"preds_blitter_neutral_riskiest_50\"].rank(pct=True) + validation_data[\"preds_blitter1_neutral_riskiest_50\"].rank(pct=True) / 2\r\n",
    "tournament_data.loc[:, f\"preds_{model_name}\"] = tournament_data[\"preds_blitter_neutral_riskiest_50\"].rank(pct=True) + tournament_data[\"preds_blitter1_neutral_riskiest_50\"].rank(pct=True) / 2\r\n",
    "\r\n",
    "model_to_submit = f\"preds_{model_name}\"\r\n",
    "\r\n",
    "#rank again to fix decimals coming from the /2\r\n",
    "validation_data[\"prediction\"] = validation_data[model_to_submit].rank(pct=True)\r\n",
    "tournament_data[\"prediction\"] = tournament_data[model_to_submit].rank(pct=True)\r\n",
    "\r\n",
    "\r\n",
    "validation_data[\"prediction\"].to_csv(f\"validation_predictions_{current_round}_{model_to_submit}.csv\")\r\n",
    "tournament_data[\"prediction\"].to_csv(f\"tournament_predictions_{current_round}_{model_to_submit}.csv\")\r\n",
    "\r\n",
    "validation_stats = validation_metrics(validation_data, [model_to_submit], example_col=EXAMPLE_PREDS_COL, fast_mode=True)\r\n",
    "print(validation_stats[[\"mean\", \"sharpe\"]].to_markdown())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "|                |      mean |   sharpe |\n",
      "|:---------------|----------:|---------:|\n",
      "| preds_BLITTER3 | 0.0236422 |  1.06787 |\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "model_name = f\"BLITTER4\"\r\n",
    "model = create_xgb_ranker(model_name)\r\n",
    "save_prediction(model, model_name, is_xgbRanker= True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "No nans in the features this week!\n",
      "v Predicting on latest data\n",
      "v Neutralizing to risky features\n",
      "|                                    |      mean |   sharpe |\n",
      "|:-----------------------------------|----------:|---------:|\n",
      "| preds_BLITTER4_neutral_riskiest_50 | 0.0217391 | 0.864442 |\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "validation_data.loc[:, f\"preds_{model_name}\"].hist()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "metadata": {},
     "execution_count": 14
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": []
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "model_name = f\"BLITTER4\"\r\n",
    "model = create_xgb_ranker(model_name)\r\n",
    "save_prediction(model, model_name, is_xgbRanker= False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "No nans in the features this week!\n",
      "v Predicting on latest data\n",
      "v Neutralizing to risky features\n",
      "|                                    |      mean |   sharpe |\n",
      "|:-----------------------------------|----------:|---------:|\n",
      "| preds_BLITTER4_neutral_riskiest_50 | 0.0217391 | 0.864442 |\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "model_name = f\"blitter5\"\r\n",
    "model = create_catboost_regressor(model_name)\r\n",
    "save_prediction(model, model_name)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "No nans in the features this week!\n",
      "v Predicting on latest data\n",
      "v Neutralizing to risky features\n",
      "|                                    |      mean |   sharpe |\n",
      "|:-----------------------------------|----------:|---------:|\n",
      "| preds_blitter5_neutral_riskiest_50 | 0.0233502 |  0.97543 |\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "model_name = f\"blitter6\"\r\n",
    "loss_function = \"QueryRMSE\"\r\n",
    "\r\n",
    "model = create_catboost_ranker(model_name, loss_function)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "predicting blitter6\n",
      "No nans in the features this week!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "save_prediction(model, model_name, use_pool =True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "v Predicting on latest data\n",
      "v Neutralizing to risky features\n",
      "|                                    |      mean |   sharpe |\n",
      "|:-----------------------------------|----------:|---------:|\n",
      "| preds_blitter6_neutral_riskiest_50 | 0.0173495 | 0.855438 |\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "model_name = f\"blitter7\"\r\n",
    "loss_function = \"PairLogit:max_pairs=100000\"\r\n",
    "\r\n",
    "model = create_catboost_ranker(model_name, loss_function)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "predicting blitter7\n",
      "No nans in the features this week!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "save_prediction(model, model_name, use_pool =True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "v Predicting on latest data\n",
      "v Neutralizing to risky features\n",
      "|                                    |      mean |   sharpe |\n",
      "|:-----------------------------------|----------:|---------:|\n",
      "| preds_blitter7_neutral_riskiest_50 | 0.0147554 | 0.726439 |\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TODO GroupKfold for non overlapping eras\r\n",
    "# optuna optimize\r\n",
    "\r\n",
    "# stacking"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "LTR over slightly neutralized target"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a85be61ea43e8b6e79189e6bca7a99912206a1ace4d1f752775c7cc0873391fd"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('numerai': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}